# Import necessary libraries
import time
import warnings
warnings.filterwarnings('ignore')
from mnist import MNIST  # For loading EMNIST dataset
import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
from sklearn.preprocessing import MinMaxScaler, OneHotEncoder
from PIL import Image

# Load and prepare the EMNIST dataset
emnist = MNIST('path_to_emnist_data')
emnist.select_emnist('balanced')
images, labels = emnist.load_training()
test_images, test_labels = emnist.load_testing()

# Convert data to numpy arrays
n_images = np.array(images)
n_labels = np.array(labels)
test_images = np.array(test_images)
test_labels = np.array(test_labels)

# Visualize sample data
plt.imshow(n_images[19000].reshape(28, 28), cmap='gist_gray')
plt.show()

# Normalize images between 0 and 1
scaler = MinMaxScaler()
train_images = scaler.fit_transform(n_images)
test_images = scaler.transform(test_images)

# Add new dataset if necessary (e.g., additional images)
# This part can be skipped if no additional images are to be added.

# One-hot encode labels
shaped_n_labels = n_labels.reshape(-1, 1)
enc = OneHotEncoder()
enc.fit(shaped_n_labels)
train_labels = enc.transform(shaped_n_labels).toarray()

shaped_test_labels = test_labels.reshape(-1, 1)
enc.fit(shaped_test_labels)
test_labels = enc.transform(shaped_test_labels).toarray()

# Define functions for model layers
def init_weights(shape):
    init_random_dist = tf.truncated_normal(shape, stddev=0.1)
    return tf.Variable(init_random_dist)

def init_bias(shape):
    init_bias_vals = tf.constant(0.1, shape=shape)
    return tf.Variable(init_bias_vals)

def conv2d(x, W):
    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')

def max_pool_2by2(x):
    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')

def convolutional_layer(input_x, shape):
    W = init_weights(shape)
    bias = init_bias([shape[3]])
    return tf.nn.relu(conv2d(input_x, W) + bias)

def normal_full_layer(input_layer, size):
    input_size = int(input_layer.get_shape()[1])
    W = init_weights([input_size, size])
    bias = init_bias([size])
    return tf.matmul(input_layer, W) + bias

# Model structure
x = tf.placeholder(tf.float32, shape=[None, 784])
y_true = tf.placeholder(tf.float32, shape=[None, 62])  # 10 digits + 26 uppercase + 26 lowercase = 62 classes

x_image = tf.reshape(x, [-1, 28, 28, 1])

# Convolutional and fully connected layers
convo_1 = convolutional_layer(x_image, shape=[5, 5, 1, 32])
convo_1_pooling = max_pool_2by2(convo_1)

convo_2 = convolutional_layer(convo_1_pooling, shape=[5, 5, 32, 64])
convo_2_pooling = max_pool_2by2(convo_2)

convo_flat = tf.reshape(convo_2_pooling, [-1, 7 * 7 * 64])
full_layer_one = tf.nn.relu(normal_full_layer(convo_flat, 1024))

# Dropout and prediction
hold_prob = tf.placeholder(tf.float32)
full_one_dropout = tf.nn.dropout(full_layer_one, keep_prob=hold_prob)

y_pred = normal_full_layer(full_one_dropout, 62)

# Loss function and optimizer
cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=y_pred))
optimizer = tf.train.AdamOptimizer(learning_rate=0.001)
train = optimizer.minimize(cross_entropy)

# Train the model
saver = tf.train.Saver()
steps = 5000

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    for i in range(steps):
        rand_ind = np.random.randint(len(train_images), size=120)
        feed = {x: train_images[rand_ind], y_true: train_labels[rand_ind], hold_prob: 0.5}
        sess.run(train, feed_dict=feed)
        
        if i % 100 == 0:
            print(f"On step: {i}")
            match = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y_true, 1))
            acc = tf.reduce_mean(tf.cast(match, tf.float32))
            print(f"Accuracy at step {i}: {sess.run(acc, feed_dict={x: test_images, y_true: test_labels, hold_prob: 1.0})}")
    
    saver.save(sess, 'model/cnn_model_1_with_alphanumeric.ckpt')

# Restore model and predict
labels_dict = {
    0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9',
    10: 'A', 11: 'B', 12: 'C', 13: 'D', 14: 'E', 15: 'F', 16: 'G', 17: 'H', 18: 'I', 19: 'J',
    20: 'K', 21: 'L', 22: 'M', 23: 'N', 24: 'O', 25: 'P', 26: 'Q', 27: 'R', 28: 'S', 29: 'T',
    30: 'U', 31: 'V', 32: 'W', 33: 'X', 34: 'Y', 35: 'Z',
    36: 'a', 37: 'b', 38: 'c', 39: 'd', 40: 'e', 41: 'f', 42: 'g', 43: 'h', 44: 'i', 45: 'j',
    46: 'k', 47: 'l', 48: 'm', 49: 'n', 50: 'o', 51: 'p', 52: 'q', 53: 'r', 54: 's', 55: 't',
    56: 'u', 57: 'v', 58: 'w', 59: 'x', 60: 'y', 61: 'z'
}

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    saver.restore(sess, "model/cnn_model_1_with_alphanumeric.ckpt")
    prediction = tf.argmax(y_pred, 1)
    
    # Example prediction using one image
    n_image = train_images[0]  # Replace with the desired image
    var = prediction.eval(feed_dict={x: [n_image], hold_prob: 1.0}, session=sess)
    print(f'The predicted character is: "{labels_dict[var[0]]}"')
